{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import heapq\n",
    "import re\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyTestTPath = 'data/origin_files/key_test_t.csv'\n",
    "df = pd.read_csv(keyTestTPath)\n",
    "# df = df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_json(json_str):\n",
    "    try:\n",
    "        json.loads(json_str)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def process_row(row):\n",
    "    if validate_json(row.dimension) and validate_json(row.results):\n",
    "        return row\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def judgeJson(keyTestT):\n",
    "    # 使用并行处理加速处理过程\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(process_row, keyTestT.itertuples()), total=len(keyTestT)))\n",
    "\n",
    "    # 过滤掉返回 None 的结果并重置索引\n",
    "    keyTestT = pd.DataFrame([r for r in results if r is not None])\n",
    "    keyTestT = keyTestT.reset_index(drop=True)\n",
    "    return keyTestT\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('data/filterFile.csv', index_col=None)\n",
    "    print('filterFile.csv exists')\n",
    "except FileNotFoundError:\n",
    "    df = df[['results', 'dimension','results_key']]\n",
    "    df = judgeJson(df)\n",
    "    df.to_csv('data/filterFile.csv', index=False)\n",
    "    print('filterFile.csv created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterFilePath = 'data/filterFile.csv'\n",
    "df = pd.read_csv(filterFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKeyNum(df):\n",
    "    # 提取 results 列中带有 \"#\" 号的字段\n",
    "    pattern = r'#\\w+'  \n",
    "    results = df['results'].str.cat(sep=' ')  # 将所有 results 列的数据合并为一个字符串\n",
    "    hashtags = set(re.findall(pattern, results))  # 使用正则表达式提取带 \"#\" 号的字段，并去重\n",
    "\n",
    "    # 统计每个带 \"#\" 号的字段在整个文件中出现的次数\n",
    "    hashtags_dict = {}\n",
    "    for hashtag in hashtags:\n",
    "        count = results.count(hashtag)\n",
    "        hashtags_dict[hashtag] = count\n",
    "    return hashtags_dict\n",
    "\n",
    "def showKeyNum(hashtags_dict):\n",
    "    # 将字典按值从大到小排序\n",
    "    hashtags_dict_sorted = sorted(hashtags_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 提取排序后的键和值\n",
    "    hashtags_sorted = [item[0] for item in hashtags_dict_sorted]\n",
    "    counts_sorted = [item[1] for item in hashtags_dict_sorted]\n",
    "\n",
    "    # 绘制柱状图\n",
    "    plt.figure(figsize=(180, 25))  \n",
    "    plt.bar(hashtags_sorted, counts_sorted)  \n",
    "    plt.xticks(rotation=90)  \n",
    "    plt.xlabel('Hashtags')  \n",
    "    plt.ylabel('Counts')  \n",
    "    plt.title('Hashtags Counts')  \n",
    "    plt.show()\n",
    "\n",
    "def getTop10Key(hashtags_dict):\n",
    "    # 获取字典中数量前十的字段\n",
    "    top_n = 10  # 自定义获取前几个字段\n",
    "    top_n_fields = heapq.nlargest(top_n, hashtags_dict, key=hashtags_dict.get)\n",
    "    \n",
    "    print(\"数量前十的字段：\")\n",
    "    for field in top_n_fields:\n",
    "        print(\"字段名: {:<30s} 出现次数: {:d}\".format(field, hashtags_dict[field]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_dict=getKeyNum(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showKeyNum(hashtags_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getTop10Key(hashtags_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValue1(df, field):\n",
    "    result_dict_values = {}\n",
    "    result_dict_values[field] = []\n",
    "    for row in df.itertuples():\n",
    "        if field in row.results:\n",
    "            try:\n",
    "                result = eval(row.results)[field]\n",
    "                result_dict_values[field].append(result)\n",
    "            except:\n",
    "                pass\n",
    "    return result_dict_values\n",
    "\n",
    "def getValue2(df, field):\n",
    "    result_dict_values = {field: df.loc[df['results'].str.contains(field), 'results'].str.extract(r'\\\"{}\\\":\\s*(\\d+)'.format(field), expand=False).dropna().astype(float).tolist()}\n",
    "    return result_dict_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unixbench_cpu\n",
    "your_field = '#unixbench_cpu'\n",
    "result_dict_values = getValue1(df, your_field)\n",
    "outPutDF = pd.DataFrame(result_dict_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outPutDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInput(keyTestT, importantKey):\n",
    "    inputList = []\n",
    "    keys_to_extract = ['cvm_cpu', 'cvm_memory', 'cvm_cpu_qos', 'cvm_os_type']\n",
    "    for i in tqdm(range(len(keyTestT))):\n",
    "        results = json.loads(keyTestT.loc[i, 'results'])\n",
    "        for result in results:\n",
    "            if importantKey in result:\n",
    "                # 将dimension中['cvm_cpu', 'cvm_memory', 'cvm_cpu_qos', 'cvm_os_type']这几个字段的值提取出来\n",
    "                dimension = json.loads(keyTestT.loc[i, 'dimension'])\n",
    "                dimension = json.dumps(dimension)\n",
    "                templist=['cvm_cpu', 'cvm_memory', 'cvm_cpu_qos', 'cvm_os_type']\n",
    "                dimensionJson = json.loads(dimension)\n",
    "                for key in dimensionJson:\n",
    "                    if key in templist:\n",
    "                        key_value = dimensionJson[key]\n",
    "                        if key=='cvm_memory':\n",
    "                            key_value=float(key_value.split(' ')[0])\n",
    "                        elif key=='cvm_cpu':\n",
    "                            key_value=float(key_value)\n",
    "                        elif key=='cvm_cpu_qos':\n",
    "                            key_value='true'\n",
    "                        templist[keys_to_extract.index(key)]=key_value\n",
    "                results_key = keyTestT.loc[i, 'results_key']\n",
    "                templist.append(results_key)\n",
    "                inputList.append(templist)\n",
    "                break\n",
    "\n",
    "    # 将inputList转换为DataFrame\n",
    "    inputDF = pd.DataFrame(inputList, columns=['cvm_cpu', 'cvm_memory', 'cvm_cpu_qos', 'cvm_os_type', 'results_key'])\n",
    "    # 判断cvm_cpu和cvm_memory是否是数字，如果不是数字则填写-1\n",
    "    inputDF['cvm_cpu'] = pd.to_numeric(inputDF['cvm_cpu'], errors='coerce').fillna(-1)\n",
    "    inputDF['cvm_memory'] = pd.to_numeric(inputDF['cvm_memory'], errors='coerce').fillna(-1)\n",
    "    return inputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDF = getInput(df, your_field)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputDF.shape)\n",
    "print(outPutDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import pickle\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPic(methodName, y_test, y_pred):\n",
    "    # 创建柱状图\n",
    "    plt.figure(figsize=(80, 15))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    # 创建样本索引数组\n",
    "    index = np.arange(len(y_test))\n",
    "    # 绘制线性回归模型的折线图\n",
    "    plt.plot(index, y_test, label='True Values')\n",
    "    plt.plot(index, y_pred, label='Predicted Values')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('{}: True Values vs. Predicted Values'.format(methodName))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def showCoef(linear_reg, decision_tree_reg, random_forest_reg):\n",
    "    # 绘制特征重要性条形图\n",
    "    if len(linear_reg.coef_) > 1:\n",
    "        coef_abs = np.abs(linear_reg.coef_)\n",
    "        sorted_idx = np.argsort(coef_abs)\n",
    "        plt.figure(figsize=(150, 20))\n",
    "        plt.bar(range(len(coef_abs)), coef_abs[sorted_idx])\n",
    "        plt.xticks(range(len(coef_abs)), sorted_idx)\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Feature Importance (by coefficient absolute value)')\n",
    "        plt.title('Linear Regression - Feature Importance')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Linear Regression - No feature importance to plot')\n",
    "\n",
    "    if len(decision_tree_reg.feature_importances_) > 1:\n",
    "        feature_importances = decision_tree_reg.feature_importances_\n",
    "        sorted_idx = np.argsort(feature_importances)\n",
    "        plt.figure(figsize=(150, 20))\n",
    "        plt.bar(range(len(feature_importances)), feature_importances[sorted_idx])\n",
    "        plt.xticks(range(len(feature_importances)), sorted_idx)\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Feature Importance')\n",
    "        plt.title('Decision Tree - Feature Importance')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Decision Tree - No feature importance to plot')\n",
    "\n",
    "    if len(random_forest_reg.feature_importances_) > 1:\n",
    "        feature_importances = random_forest_reg.feature_importances_\n",
    "        sorted_idx = np.argsort(feature_importances)\n",
    "        plt.figure(figsize=(150, 20))\n",
    "        plt.bar(range(len(feature_importances)), feature_importances[sorted_idx])\n",
    "        plt.xticks(range(len(feature_importances)), sorted_idx)\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Feature Importance')\n",
    "        plt.title('Random Forest - Feature Importance')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Random Forest - No feature importance to plot')\n",
    "\n",
    "\n",
    "def getCoef(linear_reg, decison_tree_reg, random_forest_reg):\n",
    "    result = []\n",
    "    if len(linear_reg.coef_) > 1:\n",
    "        coef_abs = np.abs(linear_reg.coef_)\n",
    "        sorted_idx = np.argsort(coef_abs)\n",
    "        # 将最后10个特征的索引存入templist中\n",
    "        templist = []\n",
    "        for i in range(1, 11):\n",
    "            templist.append(sorted_idx[-i])\n",
    "        result.append(templist)\n",
    "    else:\n",
    "        result.append([])\n",
    "    if len(decison_tree_reg.feature_importances_) > 1:\n",
    "        feature_importances = decison_tree_reg.feature_importances_\n",
    "        sorted_idx = np.argsort(feature_importances)\n",
    "        # 将最后10个特征的索引存入templist中\n",
    "        templist = []\n",
    "        for i in range(1, 11):\n",
    "            templist.append(sorted_idx[-i])\n",
    "        result.append(templist)\n",
    "    else:\n",
    "        result.append([])\n",
    "    if len(random_forest_reg.feature_importances_) > 1:\n",
    "        feature_importances = random_forest_reg.feature_importances_\n",
    "        sorted_idx = np.argsort(feature_importances)\n",
    "        # 将最后10个特征的索引存入templist中\n",
    "        templist = []\n",
    "        for i in range(1, 11):\n",
    "            templist.append(sorted_idx[-i])\n",
    "        result.append(templist)\n",
    "    else:\n",
    "        result.append([])\n",
    "    return result\n",
    "\n",
    "\n",
    "def getFeatureName(result, inputDF):\n",
    "    feature_names = inputDF.columns\n",
    "    linear_reg_indices = result[0]  # 线性回归模型的特征索引\n",
    "    decision_tree_indices = result[1]  # 决策树模型的特征索引\n",
    "    random_forest_indices = result[2]  # 随机森林模型的特征索引\n",
    "\n",
    "    linear_reg_feature_names = feature_names[linear_reg_indices].tolist()  # 线性回归模型的特征列名列表\n",
    "    decision_tree_feature_names = feature_names[decision_tree_indices].tolist()  # 决策树模型的特征列名列表\n",
    "    random_forest_feature_names = feature_names[random_forest_indices].tolist()  # 随机森林模型的特征列名列表\n",
    "    \n",
    "    linear_reg_features = inputDF[linear_reg_feature_names]  # 线性回归模型的特征值\n",
    "    decision_tree_features = inputDF[decision_tree_feature_names]  # 决策树模型的特征值\n",
    "    random_forest_features = inputDF[random_forest_feature_names]  # 随机森林模型的特征值\n",
    "\n",
    "\n",
    "def showDecisonTree(decision_tree_reg, flag=False):\n",
    "    if flag:    \n",
    "        plt.figure(figsize=(20, 10))  # 设置画布大小\n",
    "        plot_tree(decision_tree_reg, max_depth=2, feature_names=None, filled=True, rounded=True)  # 设置最大深度为2，可以根据需要调整\n",
    "        plt.title('Decision Tree')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def showRandomForest(random_forest_reg, flag=False):\n",
    "    if flag:\n",
    "        if len(random_forest_reg.feature_importances_) > 1:\n",
    "            # 获取特征重要性\n",
    "            feature_importances = random_forest_reg.feature_importances_\n",
    "            # 选择特征重要性最高的决策树\n",
    "            best_tree_index = np.argmax(feature_importances)\n",
    "            if best_tree_index >= random_forest_reg.n_estimators:\n",
    "                best_tree_index = random_forest_reg.n_estimators - 1\n",
    "\n",
    "            plt.figure(figsize=(20, 10))\n",
    "            plot_tree(random_forest_reg.estimators_[best_tree_index], max_depth=2, feature_names=None, filled=True, rounded=True)\n",
    "            plt.title('Best Decision Tree')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print('Random Forest - No feature importance to plot')\n",
    "\n",
    "\n",
    "def getModel(X_train, y_train, save_path):\n",
    "    # 初始化模型\n",
    "    linear_reg = LinearRegression()\n",
    "    decision_tree_reg = DecisionTreeRegressor()\n",
    "    random_forest_reg = RandomForestRegressor(n_estimators=100, max_depth=5)\n",
    "    svm_reg = SVR(C=1.0, epsilon=0.1)\n",
    "    knn_reg = KNeighborsRegressor(n_neighbors=10, weights='uniform')\n",
    "\n",
    "    # 拟合模型\n",
    "    linear_reg.fit(X_train, y_train)\n",
    "    decision_tree_reg.fit(X_train, y_train)\n",
    "    random_forest_reg.fit(X_train, y_train)\n",
    "    svm_reg.fit(X_train, y_train)\n",
    "    knn_reg.fit(X_train, y_train)\n",
    "\n",
    "    # 保存模型\n",
    "    models = {\n",
    "        'linear_reg': linear_reg,\n",
    "        'decision_tree_reg': decision_tree_reg,\n",
    "        'random_forest_reg': random_forest_reg,\n",
    "        'svm_reg': svm_reg,\n",
    "        'knn_reg': knn_reg\n",
    "    }\n",
    "    # save_path = 'model/'\n",
    "    for model_name, model in models.items():\n",
    "        with open(save_path + model_name + '.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    return linear_reg, decision_tree_reg, random_forest_reg, svm_reg, knn_reg\n",
    "\n",
    "\n",
    "def train(X, y, save_path):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    # 获取模型\n",
    "    linear_reg, decision_tree_reg, random_forest_reg, svm_reg, knn_reg = getModel(X_train, y_train, save_path)\n",
    "\n",
    "    # 预测\n",
    "    y_pred_linear_reg = linear_reg.predict(X_test)\n",
    "    y_pred_decision_tree_reg = decision_tree_reg.predict(X_test)\n",
    "    y_pred_random_forest_reg = random_forest_reg.predict(X_test)\n",
    "    y_pred_svm_reg = svm_reg.predict(X_test)\n",
    "    y_pred_knn_reg = knn_reg.predict(X_test)\n",
    "\n",
    "    # 计算评估指标\n",
    "    r2_linear_reg = r2_score(y_test, y_pred_linear_reg)\n",
    "    r2_decision_tree_reg = r2_score(y_test, y_pred_decision_tree_reg)\n",
    "    r2_random_forest_reg = r2_score(y_test, y_pred_random_forest_reg)\n",
    "    r2_svm_reg = r2_score(y_test, y_pred_svm_reg)\n",
    "    r2_knn_reg = r2_score(y_test, y_pred_knn_reg)\n",
    "\n",
    "    print('{:<30} {:>10}'.format('Linear Regression R2:', '{:.8f}'.format(r2_linear_reg)))\n",
    "    print('{:<30} {:>10}'.format('Decision Tree R2:', '{:.8f}'.format(r2_decision_tree_reg)))\n",
    "    print('{:<30} {:>10}'.format('Random Forest R2:', '{:.8f}'.format(r2_random_forest_reg)))\n",
    "    print('{:<30} {:>10}'.format('SVM R2:', '{:.8f}'.format(r2_svm_reg)))\n",
    "    print('{:<30} {:>10}'.format('KNN R2:', '{:.8f}'.format(r2_knn_reg)))\n",
    "    print('\\n')\n",
    "\n",
    "    models = ['Linear Regression', 'Decision Tree Regression', 'Random Forest Regression', 'SVM Regression', 'KNN Regression']\n",
    "    y_pred = ['y_pred_linear_reg', 'y_pred_decision_tree_reg', 'y_pred_random_forest_reg', 'y_pred_svm_reg', 'y_pred_knn_reg']\n",
    "    # for i in range(len(models)):\n",
    "    #     showPic(models[i], y_test, eval(y_pred[i]))\n",
    "\n",
    "    return linear_reg, decision_tree_reg, random_forest_reg, svm_reg, knn_reg\n",
    "\n",
    "\n",
    "def plot_learning_curve(model, X, y):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=5)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"b\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                     color=\"g\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def judgeResult(model, X_train, y_train, X_test, y_test):\n",
    "    # 在训练集和测试集上计算评估指标\n",
    "    y_train = y_train.values\n",
    "    y_test = y_test.values\n",
    "    y_train = y_train.ravel()\n",
    "    y_test = y_test.ravel()\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    print('Model: {}'.format(model.__class__.__name__))\n",
    "    print('{:<30} {:>10}'.format('Train R2:', '{:.8f}'.format(r2_train)))\n",
    "    print('{:<30} {:>10}'.format('Test R2:', '{:.8f}'.format(r2_test)))\n",
    "    \n",
    "    # 绘制学习曲线\n",
    "    plot_learning_curve(model, X_train, y_train)\n",
    "\n",
    "    # 判断过拟合\n",
    "    if r2_test > r2_train:\n",
    "        print(\"模型可能存在过拟合的问题\\n\\n\")\n",
    "    else:\n",
    "        print(\"模型可能没有过拟合的问题\\n\\n\")\n",
    "\n",
    "\n",
    "def trainOverFit(X, y, save_path):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    # 获取模型\n",
    "    linear_reg, decision_tree_reg, random_forest_reg, svm_reg, knn_reg = getModel(X_train, y_train, save_path)\n",
    "\n",
    "    # 预测\n",
    "\n",
    "    y_pred_linear_reg = linear_reg.predict(X_test)\n",
    "    y_pred_decision_tree_reg = decision_tree_reg.predict(X_test)\n",
    "    y_pred_random_forest_reg = random_forest_reg.predict(X_test)\n",
    "    y_pred_svm_reg = svm_reg.predict(X_test)\n",
    "    y_pred_knn_reg = knn_reg.predict(X_test)\n",
    "\n",
    "    # 计算评估指标\n",
    "    r2_linear_reg = r2_score(y_test, y_pred_linear_reg)\n",
    "    r2_decision_tree_reg = r2_score(y_test, y_pred_decision_tree_reg)\n",
    "    r2_random_forest_reg = r2_score(y_test, y_pred_random_forest_reg)\n",
    "    r2_svm_reg = r2_score(y_test, y_pred_svm_reg)\n",
    "    r2_knn_reg = r2_score(y_test, y_pred_knn_reg)\n",
    "\n",
    "    print('{:<30} {:>10}'.format('Linear Regression R2:', '{:.8f}'.format(r2_linear_reg)))\n",
    "    print('{:<30} {:>10}'.format('Decision Tree R2:', '{:.8f}'.format(r2_decision_tree_reg)))\n",
    "    print('{:<30} {:>10}'.format('Random Forest R2:', '{:.8f}'.format(r2_random_forest_reg)))\n",
    "    print('{:<30} {:>10}'.format('SVM R2:', '{:.8f}'.format(r2_svm_reg)))\n",
    "    print('{:<30} {:>10}'.format('KNN R2:', '{:.8f}'.format(r2_knn_reg)))\n",
    "    print('\\n')\n",
    "\n",
    "    models = ['Linear Regression', 'Decision Tree Regression', 'Random Forest Regression', 'SVM Regression', 'KNN Regression']\n",
    "    y_pred = [y_pred_linear_reg, y_pred_decision_tree_reg, y_pred_random_forest_reg, y_pred_svm_reg, y_pred_knn_reg]\n",
    "    # for i in range(len(models)):\n",
    "    #     showPic(models[i], y_test, y_pred[i])\n",
    "\n",
    "    getModelList = ['linear_reg', 'decision_tree_reg', 'random_forest_reg', 'svm_reg', 'knn_reg']\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        judgeResult(eval(getModelList[i]), X_train, y_train, X_test, y_test)\n",
    "\n",
    "    return linear_reg, decision_tree_reg, random_forest_reg, svm_reg, knn_reg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDF['cvm_cpu'] = pd.to_numeric(inputDF['cvm_cpu'])\n",
    "inputDF['cvm_memory'] = pd.to_numeric(inputDF['cvm_memory'])\n",
    "one_hot_df = pd.get_dummies(inputDF, columns=['cvm_cpu_qos', 'cvm_os_type','results_key'])\n",
    "X = one_hot_df\n",
    "y = outPutDF\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  观察训练集和测试集上的模型性能：如果模型在训练集上表现很好但在测试集上表现较差，可能是模型过拟合了。可以通过比较训练集和测试集上的评估指标（如R2分数）来观察模型的性能差异。如果模型在训练集上的性能远远优于测试集，可能存在过拟合的问题。\n",
    "\n",
    "2.  绘制学习曲线：可以绘制模型的学习曲线，观察模型在训练集和测试集上的性能随着训练样本数量增加而变化。如果模型在训练集上的性能持续提高而在测试集上的性能趋于稳定，可能存在过拟合的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'model/'\n",
    "# 判断是否有这个文件夹，没有就创建 \n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# linear_reg, decision_tree_reg, random_forest_reg, svm_reg, knn_reg = trainOverFit(X, y, save_path)\n",
    "\n",
    "linear_reg, decision_tree_reg, random_forest_reg, svm_reg, knn_reg = train(X, y, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showCoef(linear_reg, decision_tree_reg, random_forest_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultCoef = getCoef(linear_reg, decision_tree_reg, random_forest_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureName(X, result):\n",
    "    feature_names = X.columns\n",
    "    linear_reg_indices = result[0]  # 线性回归模型的特征索引\n",
    "    decision_tree_indices = result[1]  # 决策树模型的特征索引\n",
    "    random_forest_indices = result[2]  # 随机森林模型的特征索引\n",
    "    resDict={}\n",
    "    if len(linear_reg_indices) > 0:\n",
    "        print('linear_reg_index: ', linear_reg_indices)\n",
    "        linear_reg_feature_names = feature_names[linear_reg_indices].tolist()\n",
    "        print('linear_reg_feature_names: ', linear_reg_feature_names)\n",
    "        resDict['linear_reg_feature_names']=linear_reg_feature_names\n",
    "    if len(decision_tree_indices) > 0:\n",
    "        print('decision_tree_reg_index: ', decision_tree_indices)\n",
    "        decision_tree_feature_names = feature_names[decision_tree_indices].tolist()\n",
    "        print('decision_tree_feature_names: ', decision_tree_feature_names)\n",
    "        resDict['decision_tree_feature_names']=decision_tree_feature_names\n",
    "    if len(random_forest_indices) > 0:\n",
    "        print('random_forest_reg_index: ', random_forest_indices)\n",
    "        random_forest_feature_names = feature_names[random_forest_indices].tolist()\n",
    "        print('random_forest_feature_names: ', random_forest_feature_names)\n",
    "        resDict['random_forest_feature_names']=random_forest_feature_names\n",
    "    return resDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureImportDict=getFeatureName(X, resultCoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FeatureImportDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树信息理解\n",
    "x[14]<=0.5：表示该节点的分裂条件，其中 x[14] 表示特征的索引（通常是在训练数据中的列的索引），0.5 是用于划分特征值的阈值。这表示如果样本的第 14 个特征值小于或等于 0.5，则按照左子树的路径进行分裂，否则按照右子树的路径进行分裂。\n",
    "\n",
    "mse = 123432345：表示该节点的均方误差（Mean Squared Error, MSE），是在该节点处使用的用于评估分裂效果的指标。MSE 是决策树模型常用的一个评估指标，用于衡量当前节点的预测误差。\n",
    "\n",
    "samples = 35：表示在该节点处参与训练的样本数量，即经过该节点的样本数量。\n",
    "\n",
    "value = 2132232：表示在该节点处的预测值，通常是该节点处样本的目标变量（或标签）的平均值。这个值可以作为决策树模型对样本的预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印决策树\n",
    "showDecisonTree(decision_tree_reg, flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印随机森林\n",
    "showRandomForest(random_forest_reg, flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processUnknowData1(testX):\n",
    "    # processUnknowData1用于处理testX数据中所有的类别特征都在训练数据中出现过的情况\n",
    "    testX_one_hot = pd.get_dummies(testX, columns=['cvm_cpu_qos', 'cvm_os_type', 'results_key'])\n",
    "    # 筛选出 testX_one_hot 中在 inputDF 中出现的列\n",
    "    common_columns = testX_one_hot.columns.intersection(inputDF.columns)\n",
    "    # 使用筛选后的列重新生成 testX\n",
    "    testX = testX_one_hot[common_columns]\n",
    "\n",
    "    # 将训练数据和测试数据合并后再进行独热编码\n",
    "    combined_df = pd.concat([inputDF, testX], axis=0)\n",
    "    one_hot_df = pd.get_dummies(combined_df, columns=['cvm_cpu_qos', 'cvm_os_type', 'results_key'], dummy_na=False)\n",
    "\n",
    "    # 分割合并后的数据，得到编码后的测试数据\n",
    "    testX = one_hot_df.iloc[-1, :].values.reshape(1, -1)\n",
    "    print(testX.shape)\n",
    "    return testX\n",
    "\n",
    "\n",
    "def processUnknowData2(testX):\n",
    "    # processUnknowData2用于处理testX数据中可能包含了训练数据集中不存在的类别值\n",
    "    testDict = {'cvm_cpu': '96', 'cvm_memory': '376', 'cvm_cpu_qos': 'cvm_cpu_qos', 'cvm_os_type': 'CentOS Linux release 7.6.181dsfsd0 (Core)', 'results_key': 'gcc_oflsdfsfdag=O3,threads=1'}\n",
    "\n",
    "    for i, key in enumerate(testDict.keys()):\n",
    "        testDict[key] = testX[i]\n",
    "\n",
    "    max_key_length = max(len(key) for key in testDict.keys())\n",
    "    for key, value in testDict.items():\n",
    "        print('key: {:<{}} \\tvalue: {}'.format(key, max_key_length, value))\n",
    "\n",
    "    testDict = pd.DataFrame(testDict, index=[0])\n",
    "    testDict['cvm_cpu'] = pd.to_numeric(testDict['cvm_cpu'])\n",
    "    testDict['cvm_memory'] = pd.to_numeric(testDict['cvm_memory'])\n",
    "    one_hot_df = pd.get_dummies(testDict, columns=['cvm_cpu_qos', 'cvm_os_type', 'results_key'], dummy_na=False)\n",
    "\n",
    "    # 获取 inputDF 中的特征列顺序\n",
    "    inputDF_columns = X.columns.tolist()\n",
    "    # 添加缺失的列，并将其值设置为 0\n",
    "    missing_columns = list(set(inputDF_columns) - set(one_hot_df.columns))\n",
    "    for column in missing_columns:\n",
    "        one_hot_df[column] = 0\n",
    "\n",
    "    # 按照 inputDF 列的顺序重新排列 one_hot_df\n",
    "    one_hot_df = one_hot_df[inputDF_columns]\n",
    "\n",
    "    # 确保编码后的维度与 inputDF 一致\n",
    "    testX_encoded = one_hot_df.values.reshape(1, -1)\n",
    "    print(testX_encoded.shape)\n",
    "    return testX_encoded\n",
    "\n",
    "\n",
    "def processData(testX, num):\n",
    "    if num == 1:\n",
    "        testX = processUnknowData1(testX)\n",
    "    elif num == 2:\n",
    "        testX = processUnknowData2(testX)\n",
    "    else:\n",
    "        print('num must be 1 or 2')\n",
    "    return testX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = ['8','40','true','CentOS Linux release 7.3.1611 (Core)','gcc_oflag=O0,threads=1']\n",
    "testY = 2364\n",
    "testX_encoded = processData(testX, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, load_path):\n",
    "    # 加载保存的模型\n",
    "    model = ['linear_reg', 'decision_tree_reg', 'random_forest_reg', 'svm_reg', 'knn_reg']\n",
    "    result = []\n",
    "    for model_name in model:\n",
    "        with open(os.path.join(load_path, model_name + '.pkl'), 'rb') as f:\n",
    "            models = pickle.load(f)\n",
    "        preRes = models.predict(X)\n",
    "        result.append(preRes)\n",
    "\n",
    "    numbers = [item.item() if isinstance(item, np.ndarray) and item.size == 1 else item for sublist in result for item in sublist]\n",
    "\n",
    "    predictions = {}\n",
    "    for i in range(len(model)):\n",
    "        predictions[model[i]] = numbers[i]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def plot_predictions(predictions, y):\n",
    "    keys = list(predictions.keys())\n",
    "    values = list(predictions.values())\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "        \n",
    "    # 生成 x 轴的位置\n",
    "    ind = np.arange(len(keys))\n",
    "    \n",
    "    # 设置柱状图的宽度\n",
    "    width = 0.35\n",
    "    \n",
    "    # 用 plt 画柱状图，x 轴是 predictions 的 key，y 轴是 predictions 的 value 和 y 的值，一个 x 轴对应两个柱子\n",
    "    plt.bar(ind, values, width, label='Predictions')\n",
    "    plt.bar(ind + width, y, width, label='Actual')\n",
    "    \n",
    "    # 设置 x 轴标签和标题\n",
    "    plt.xticks(ind + width / 2, keys)\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Model Predictions vs Actual Value')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(testX_encoded, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(predictions, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMultiModel(X_train, y_train, save_path):\n",
    "    # 初始化模型\n",
    "    linear_reg = LinearRegression()\n",
    "    decision_tree_reg = DecisionTreeRegressor()\n",
    "    random_forest_reg = RandomForestRegressor(n_estimators=100, max_depth=5)\n",
    "    svm_reg = SVR(C=1.0, epsilon=0.1)\n",
    "    knn_reg = KNeighborsRegressor(n_neighbors=10, weights='uniform')\n",
    "\n",
    "    # 使用MultiOutputRegressor包装模型\n",
    "    multioutput_linear_reg = MultiOutputRegressor(linear_reg)\n",
    "    multioutput_decision_tree_reg = MultiOutputRegressor(decision_tree_reg)\n",
    "    multioutput_random_forest_reg = MultiOutputRegressor(random_forest_reg)\n",
    "    multioutput_svm_reg = MultiOutputRegressor(svm_reg)\n",
    "    multioutput_knn_reg = MultiOutputRegressor(knn_reg)\n",
    "\n",
    "    # 拟合模型\n",
    "    multioutput_linear_reg.fit(X_train, y_train)\n",
    "    multioutput_decision_tree_reg.fit(X_train, y_train)\n",
    "    multioutput_random_forest_reg.fit(X_train, y_train)\n",
    "    multioutput_svm_reg.fit(X_train, y_train)\n",
    "    multioutput_knn_reg.fit(X_train, y_train)\n",
    "\n",
    "    # 保存模型\n",
    "    models = {\n",
    "        'multioutput_linear_reg': multioutput_linear_reg,\n",
    "        'multioutput_decision_tree_reg': multioutput_decision_tree_reg,\n",
    "        'multioutput_random_forest_reg': multioutput_random_forest_reg,\n",
    "        'multioutput_svm_reg': multioutput_svm_reg,\n",
    "        'multioutput_knn_reg': multioutput_knn_reg\n",
    "    }\n",
    "    # save_path = 'model/'\n",
    "    for model_name, model in models.items():\n",
    "        with open(save_path + model_name + '.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    return multioutput_linear_reg, multioutput_decision_tree_reg, multioutput_random_forest_reg, multioutput_svm_reg, multioutput_knn_reg\n",
    "\n",
    "\n",
    "def trainMulti(X, y, save_path):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    # 获取模型\n",
    "    multioutput_linear_reg, multioutput_decision_tree_reg, multioutput_random_forest_reg, multioutput_svm_reg, multioutput_knn_reg = getMultiModel(X_train, y_train, save_path)\n",
    "\n",
    "    # 预测\n",
    "    y_pred_multioutput_linear_reg = multioutput_linear_reg.predict(X_test)\n",
    "    y_pred_multioutput_decision_tree_reg = multioutput_decision_tree_reg.predict(X_test)\n",
    "    y_pred_multioutput_random_forest_reg = multioutput_random_forest_reg.predict(X_test)\n",
    "    y_pred_multioutput_svm_reg = multioutput_svm_reg.predict(X_test)\n",
    "    y_pred_multioutput_knn_reg = multioutput_knn_reg.predict(X_test)\n",
    "\n",
    "    # 计算评估指标\n",
    "    r2_multioutput_linear_reg = r2_score(y_test, y_pred_multioutput_linear_reg)\n",
    "    r2_multioutput_decision_tree_reg = r2_score(y_test, y_pred_multioutput_decision_tree_reg)\n",
    "    r2_multioutput_random_forest_reg = r2_score(y_test, y_pred_multioutput_random_forest_reg)\n",
    "    r2_multioutput_svm_reg = r2_score(y_test, y_pred_multioutput_svm_reg)\n",
    "    r2_multioutput_knn_reg = r2_score(y_test, y_pred_multioutput_knn_reg)\n",
    "    \n",
    "    print('{:<30} {}'.format('Multi-Output Linear Regression R2:', r2_multioutput_linear_reg))\n",
    "    print('{:<30} {}'.format('Multi-Output Decision Tree R2:', ', '.join('{:.8f}'.format(x) for x in np.nditer(r2_multioutput_decision_tree_reg))))\n",
    "    print('{:<30} {}'.format('Multi-Output Random Forest R2:', ', '.join('{:.8f}'.format(x) for x in np.nditer(r2_multioutput_random_forest_reg))))\n",
    "    print('{:<30} {}'.format('Multi-Output SVM R2:', ', '.join('{:.8f}'.format(x) for x in np.nditer(r2_multioutput_svm_reg))))\n",
    "    print('{:<30} {}'.format('Multi-Output KNN R2:', ', '.join('{:.8f}'.format(x) for x in np.nditer(r2_multioutput_knn_reg))))\n",
    "\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_field1 = '#super_pi_real_time'\n",
    "result_dict_values1 = getValue1(df, your_field1)\n",
    "your_field2 = '#super_pi_sys_time'\n",
    "result_dict_values2 = getValue1(df, your_field2)\n",
    "\n",
    "result_dict_values1_list = result_dict_values1[your_field1]\n",
    "result_dict_values2_list = result_dict_values2[your_field2]\n",
    "\n",
    "# 列名设置为super_pi_real_time和super_pi_sys_time\n",
    "df1 = pd.DataFrame(result_dict_values1_list, columns=['super_pi_real_time'])\n",
    "df2 = pd.DataFrame(result_dict_values2_list, columns=['super_pi_sys_time'])\n",
    "# 将df1和df2合并为df3\n",
    "outPutDFMulti = pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outPutDFMulti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDF = getInput(df, your_field1)\n",
    "print(inputDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDF['cvm_cpu'] = pd.to_numeric(inputDF['cvm_cpu'])\n",
    "inputDF['cvm_memory'] = pd.to_numeric(inputDF['cvm_memory'])\n",
    "one_hot_df = pd.get_dummies(inputDF, columns=['cvm_cpu_qos', 'cvm_os_type','results_key'])\n",
    "X = one_hot_df\n",
    "y = outPutDFMulti\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'model/'\n",
    "# 判断是否有这个文件夹，没有就创建\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "trainMulti(X, y, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
